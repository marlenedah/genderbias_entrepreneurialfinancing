{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c0cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "# Graphs libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "#import plotly.offline as py\n",
    "#py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "#Fairlearn and imblearn \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#scklearn \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#AIF360\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.sklearn.metrics import equal_opportunity_difference\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af372ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "def compute_metrics(dataset_true, dataset_pred, \n",
    "                    unprivileged_groups, privileged_groups,\n",
    "                    disp = True):\n",
    "    \"\"\" Compute the key metrics \"\"\"\n",
    "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
    "                                                 dataset_pred, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Accuracy\"] = classified_metric_pred.accuracy()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Average absolute odds difference\"] = classified_metric_pred.average_abs_odds_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Statistical parity difference (mean difference)\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
    "    metrics[\"Consistency\"] = classified_metric_pred.consistency()\n",
    "    ##ADD MORE METRICS FROM CLASSIFICATIONMETRIC HERE\n",
    "    if disp:\n",
    "        for k in metrics:\n",
    "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd17549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "data = pd.read_csv('dataset_ready2.csv') \n",
    "data = data.set_index('ORG_org_uuid')\n",
    "\n",
    "#More cleaning\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)\n",
    "data_orig = data.copy()\n",
    "#data = data.drop(data[data.unknown_founders != 0].index)\n",
    "data = data.query('unknown_founders == 0 and female_founders != 0 or male_founders != 0')\n",
    "\n",
    "data = data.drop(data[data.total_num_founders > 10].index)\n",
    "data = data.drop(data[data.status == 'operating'].index)\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400d308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['company_name', 'category_list', 'category_group_list',\n",
    "               'region', 'city', 'homepage_url', 'founded_on', 'male_founders', 'female_founders'\n",
    "               ,'unknown_founders']\n",
    "data.drop(columns = cols_to_drop, inplace = True)\n",
    "#data_bef_scale = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da5ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 5038, 1: 13429})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CREATE A BINARY OUTCOME VARIABLE\n",
    "#y_variable_bin = y_variable.replace('operating', 1, regex = True)\n",
    "data.replace('ipo', 1, regex = True, inplace = True)\n",
    "data.replace('acquired', 1, regex = True, inplace = True)\n",
    "data.replace('closed', 0, regex = True, inplace = True)\n",
    "Counter(data.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31383e14",
   "metadata": {},
   "source": [
    "### Transform to AIF360 compatible data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46841729",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'mostly_male_founders': 1}]\n",
    "unprivileged_groups = [{'mostly_male_founders': 0}]\n",
    "\n",
    "\n",
    "dataset_orig = StandardDataset(data, \n",
    "                          label_name='status', \n",
    "                          favorable_classes=[1], \n",
    "                          protected_attribute_names=['mostly_male_founders'], \n",
    "                          privileged_classes=[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d04b6",
   "metadata": {},
   "source": [
    "### Split into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "095e1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.75], shuffle=True, seed = 10)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.2], shuffle=True, seed = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5864883",
   "metadata": {},
   "source": [
    "### Metric for the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fe749c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes = -0.074371\n",
      "Disparate Impact = 0.898739\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes = -0.076516\n",
      "Disparate Impact = 0.896921\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes = %f\" % metric_orig_train.mean_difference())\n",
    "print(\"Disparate Impact = %f\" %metric_orig_train.disparate_impact())\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"Difference in mean outcomes = %f\" % metric_orig_test.mean_difference())\n",
    "print(\"Disparate Impact = %f\" %metric_orig_test.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539ca48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa9865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = LFR(unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
    "fit_learn = learning.fit(dataset_orig_train)\n",
    "dataset_orig_train = learning.transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd5b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a6a540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier and predictions\n",
    "scale_orig = MinMaxScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "w_train = dataset_orig_train.instance_weights.ravel()\n",
    "\n",
    "lmod = LogisticRegression(solver='liblinear')\n",
    "lmod.fit(X_train, y_train, \n",
    "         sample_weight=dataset_orig_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "dataset_orig_train_pred = dataset_orig_train.copy()\n",
    "dataset_orig_train_pred.labels = y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdcf2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "y_valid = dataset_orig_valid_pred.labels\n",
    "dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "y_test = dataset_orig_test_pred.labels\n",
    "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5fddbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy (no reweighing) = 0.4966\n",
      "Optimal classification threshold (no reweighing) = 0.0793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Scores for original validation and test sets \n",
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
    "    dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "    dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                             dataset_orig_valid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "print(\"Best balanced accuracy (no reweighing) = %.4f\" % np.max(ba_arr))\n",
    "print(\"Optimal classification threshold (no reweighing) = %.4f\" % best_class_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101ad009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Predictions from original testing data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification threshold used = 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████                                         | 9/100 [00:01<00:13,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5628\n",
      "Balanced accuracy = 0.4873\n",
      "Average odds difference = 0.2393\n",
      "Average absolute odds difference = 0.2393\n",
      "Disparate impact = 1.3818\n",
      "Statistical parity difference (mean difference) = 0.2407\n",
      "Equal opportunity difference = 0.2396\n",
      "Theil index = 0.3521\n",
      "Consistency = 0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 100/100 [00:14<00:00,  7.08it/s]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Predictions from original testing data\"))\n",
    "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
    "for thresh in tqdm(class_thresh_arr):\n",
    "    \n",
    "    if thresh == best_class_thresh:\n",
    "        disp = True\n",
    "    else:\n",
    "        disp = False\n",
    "    \n",
    "    fav_inds = dataset_orig_test_pred.scores > thresh\n",
    "    dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "    dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "    \n",
    "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = disp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc1671",
   "metadata": {},
   "source": [
    "## Train with and transform the original training data - Reweighing \n",
    "\"Reweighing won't change the training data at all, rather it will learn new weights for each training row that will make the mean difference in outcomes between the specified groups 0.\"\n",
    "https://www.kaggle.com/garethjns/titanicsexism-fairness-in-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89954eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b856218",
   "metadata": {},
   "source": [
    "### Metric with the reweighed training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf21eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n",
    "assert np.abs(metric_transf_train.mean_difference()) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9139d0",
   "metadata": {},
   "source": [
    "## Train classifier on transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e04daf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_train.features)\n",
    "y_train = dataset_transf_train.labels.ravel()\n",
    "\n",
    "lmod = LogisticRegression(solver='liblinear')\n",
    "lmod.fit(X_train, y_train,\n",
    "        sample_weight=dataset_transf_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd865ba9",
   "metadata": {},
   "source": [
    "### Obtain scores for transformed test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1f5c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_transf.fit_transform(dataset_transf_test_pred.features)\n",
    "\n",
    "\n",
    "y_test = dataset_transf_test_pred.labels\n",
    "dataset_transf_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac88e7",
   "metadata": {},
   "source": [
    "## Predictions from the transformed test set at the optimal classification threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881e0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification threshold used = 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████                                         | 9/100 [00:01<00:15,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7225\n",
      "Balanced accuracy = 0.5784\n",
      "Average odds difference = 0.0199\n",
      "Average absolute odds difference = 0.0203\n",
      "Disparate impact = 1.0009\n",
      "Statistical parity difference (mean difference) = 0.0007\n",
      "Equal opportunity difference = -0.0004\n",
      "Theil index = 0.1378\n",
      "Consistency = 0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 100/100 [00:14<00:00,  7.09it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
    "for thresh in tqdm(class_thresh_arr):\n",
    "    \n",
    "    if thresh == best_class_thresh:\n",
    "        disp = True\n",
    "    else:\n",
    "        disp = False\n",
    "    \n",
    "    fav_inds = dataset_transf_test_pred.scores > thresh\n",
    "    dataset_transf_test_pred.labels[fav_inds] = dataset_transf_test_pred.favorable_label\n",
    "    dataset_transf_test_pred.labels[~fav_inds] = dataset_transf_test_pred.unfavorable_label\n",
    "    \n",
    "    metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93832d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d5a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957c333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220be35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adef7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea58bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5f141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519d8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8237b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727584b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49975aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1549bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
